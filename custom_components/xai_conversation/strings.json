{
  "config": {
    "step": {
      "user": {
        "title": "xAI Grok Setup",
        "description": "Set up your xAI Grok integration for Home Assistant. Configure your API key, endpoint, default assistant name, and search mode. Additional settings like extended tools, memory parameters, and conversation-specific configurations can be adjusted later.",
        "data": {
          "api_key": "API Key",
          "api_host": "API Endpoint (default: 'api.x.ai')",
          "assistant_name": "Assistant Name",
          "live_search": "Live Search Mode"
        },
        "data_description": {
          "api_key": "Your xAI API key (starts with 'xai-')",
          "api_host": "API endpoint hostname. Use 'api.x.ai' for global routing or a specific regional endpoint: 'us-east-1.api.x.ai' or 'eu-west-1.api.x.ai'. This endpoint is used globally across all agents.",
          "assistant_name": "The name your assistant will use to identify itself (e.g., 'Jarvis', 'Alexa', 'HAL').",
          "live_search": "Enable web search capabilities: 'off' (disabled), 'web search', 'x search', 'full' (web + x + code)"
        }
      }
    },
    "error": {
      "invalid_api_key": "Invalid API key. It must start with 'xai-'",
      "missing_dependency": "Required dependency 'xai_sdk' is not installed.",
      "unknown": "An unexpected error occurred. Please try again."
    },
    "create_entry": {
      "default": "xAI Grok integration successfully configured!"
    }
  },
  "options": {
    "error": {
      "invalid_yaml": "Invalid YAML configuration. Please check the syntax and required fields."
    },
    "step": {
      "init": {
        "title": "xAI Configuration",
        "description": "Configure memory parameters for users and devices, and set up extended custom tools. The integration automatically detects if a request comes from a user (smartphone/PC/tablet) or a device (voice satellite) and applies the appropriate memory settings.",
        "data": {
          "api_host": "API Endpoint",
          "use_extended_tools": "Enable Extended Tools Configuration",
          "extended_tools_yaml": "Extended Tools YAML Configuration",
          "memory_user_ttl_hours": "User memory TTL (hours)",
          "memory_user_max_turns": "User memory max turns",
          "memory_device_ttl_hours": "Device memory TTL (hours)",
          "memory_device_max_turns": "Device memory max turns",
          "memory_cleanup_interval_hours": "Memory cleanup interval (hours)"
        },
        "data_description": {
          "api_host": "API endpoint hostname. Use 'api.x.ai' for global routing or a specific regional endpoint: 'us-east-1.api.x.ai' or 'eu-west-1.api.x.ai'.",
          "use_extended_tools": "Enable to configure custom tools in Extended OpenAI Conversation format. When enabled, these tools will be available to all conversation agents that support extended tools.",
          "extended_tools_yaml": "Define your custom tools here. The format is fully compatible with Extended OpenAI Conversation. You can copy/paste your existing configuration.",
          "memory_user_ttl_hours": "Time-to-live for user conversations (smartphones, PCs, tablets). Default: 720 hours (30 days)",
          "memory_user_max_turns": "Maximum conversation turns stored for users. Default: 1000 turns",
          "memory_device_ttl_hours": "Time-to-live for device conversations (voice assistant satellites). Default: 168 hours (7 days)",
          "memory_device_max_turns": "Maximum conversation turns stored for devices. Default: 100 turns",
          "memory_cleanup_interval_hours": "How often expired memory entries are cleaned up. Default: 24 hours"
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "initiate_flow": {
        "user": "Add conversational agent",
        "reconfigure": "Reconfigure conversational agent"
      },
      "entry_type": "conversation",
      "step": {
        "init": {
          "title": "xAI Conversation",
          "data": {
            "name": "Name",
            "assistant_name": "Assistant Name",
            "chat_model": "Model",
            "max_tokens": "Max tokens",
            "temperature": "Temperature",
            "top_p": "Top P",
            "use_intelligent_pipeline": "Enable Intelligent Pipeline",
            "prompt": "Prompt",
            "pipeline_prompt": "Pipeline instructions (appended to default)",
            "allow_smart_home_control": "Allow smart home control",
            "live_search": "Live Search Mode",
            "store_messages": "Store messages",
            "send_user_name": "Include user name in messages",
            "show_citations": "Show citations in chat",
            "reasoning_effort": "Reasoning effort",
            "use_extended_tools": "Use Extended Tools (Global Config)"
          },
          "data_description": {
            "assistant_name": "The name your assistant will use to identify itself (e.g., 'Jarvis', 'Alexa', 'HAL'). Changing this will start a new conversation and previous chat history will not be accessible.",
            "chat_model": "Select the Grok model to use",
            "max_tokens": "Maximum number of tokens to generate",
            "temperature": "Controls randomness in responses (0.0 = deterministic, 2.0 = very creative)",
            "top_p": "Controls diversity via nucleus sampling (not supported by grok-4)",
            "use_intelligent_pipeline": "Enables a smart mode to automatically route commands to Home Assistant or provide conversational answers. If disabled, relies on the standard 'Home Assistant LLM API' for tool usage.",
            "pipeline_prompt": "Optional text appended to the default pipeline prompt. Use it for custom intents or local rules.",
            "allow_smart_home_control": "When enabled, your assistant can execute smart home commands. When disabled, your assistant responds conversationally without controlling devices. Changing this setting will start a new conversation.",
            "store_messages": "Use xAI's server-side memory, which allows you to reduce the number of tokens sent with each request. Memory parameters (TTL, max turns) are configured at integration level.",
            "send_user_name": "Add the Home Assistant user name or Assist voice device name to the chat with Grok.",
            "show_citations": "Append search citations to chat responses. Useful for UI/chat interfaces but can be noisy for voice assistants. Default: OFF (recommended for voice).",
            "live_search": "Enable agentic search capabilities: 'off' (disabled), 'web search', 'x search', 'full' (web + x + code). Applies to both pipeline and tools modes.",
            "prompt": "Custom instructions for the agent (tools mode only).",
            "reasoning_effort": "Level of reasoning effort for models that support it (low, medium, high, max). Only available for grok-4 and grok-4-fast models.",
            "use_extended_tools": "Enable the use of custom tools defined in the main integration options (Extended OpenAI format). WARNING: Enabling this will disable standard Home Assistant native tools for this agent, regardless of mode."
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Configuration updated successfully!"
      }
    },
    "sensors": {
      "initiate_flow": {
        "user": "Add token sensors",
        "reconfigure": "Reconfigure token sensors"
      },
      "entry_type": "sensor",
      "step": {
        "init": {
          "title": "xAI Token Sensors",
          "data": {
            "name": "Name",
            "tokens_per_million": "Tokens per million",
            "xai_pricing_conversion_factor": "xAI pricing conversion factor",
            "pricing_update_interval_hours": "Pricing update interval (hours)",
            "cost_per_tool_call": "Cost per tool invocation (USD)"
          },
          "data_description": {
            "name": "Descriptive name for the token sensors.",
            "tokens_per_million": "Division factor for token pricing calculations. Default: 1,000,000.",
            "xai_pricing_conversion_factor": "xAI API returns prices in units that need conversion to USD per million tokens. Default: 10,000.",
            "pricing_update_interval_hours": "How often to fetch updated pricing from xAI API. Default: 48 hours.",
            "cost_per_tool_call": "Default cost per server-side tool invocation (used as fallback if tool not in pricing map). Most tools cost $5.00/1k calls = 0.005, Collections Search costs $2.50/1k = 0.0025. Default: 0.005."
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Configuration updated successfully!"
      }
    },
    "ai_task": {
      "initiate_flow": {
        "user": "Add AI task",
        "reconfigure": "Reconfigure AI task"
      },
      "entry_type": "ai_task",
      "step": {
        "init": {
          "title": "xAI AI Task",
          "data": {
            "name": "Name",
            "prompt": "Prompt",
            "vision_prompt": "Vision Prompt",
            "chat_model": "Model",
            "image_model": "Image Model",
            "vision_model": "Vision Model",
            "max_tokens": "Max tokens",
            "temperature": "Temperature",
            "top_p": "Top P"
          },
          "data_description": {
            "name": "Descriptive name for this AI task",
            "prompt": "The entire system prompt for the AI task. This replaces the default. Be careful when editing, as it defines the task's behavior (e.g., JSON output format).",
            "vision_prompt": "System prompt for photo analysis. Defines how the vision model should analyze images (e.g., concise, detailed, factual).",
            "chat_model": "Select the Grok model to use",
            "image_model": "Model used exclusively for image generation",
            "vision_model": "Model used exclusively for photo analysis (documents, diagrams, charts, screenshots, photographs)",
            "max_tokens": "Maximum number of tokens to generate",
            "temperature": "Controls randomness in responses (0.0 = deterministic, 2.0 = very creative)",
            "top_p": "Controls diversity via nucleus sampling (not supported by grok-4)"
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Configuration updated successfully!"
      }
    },
    "task_code": {
      "initiate_flow": {
        "user": "Add Grok Code Fast",
        "reconfigure": "Reconfigure Grok Code Fast"
      },
      "entry_type": "code_fast",
      "step": {
        "init": {
          "title": "Grok Code Fast",
          "data": {
            "name": "Name",
            "prompt_code": "Custom Instructions",
            "chat_model": "Model",
            "max_tokens": "Max tokens",
            "temperature": "Temperature",
            "top_p": "Top P",
            "live_search": "Live Search Mode",
            "store_messages": "Store messages",
            "assistant_name": "Assistant name",
            "reasoning_effort": "Reasoning effort"
          },
          "data_description": {
            "name": "Descriptive name for this Grok Code Fast",
            "prompt_code": "Optional custom instructions appended to the default prompt. Use this for project-specific rules or coding conventions. Leave empty to use only the default prompt.",
            "chat_model": "Select the Grok model to use",
            "max_tokens": "Maximum number of tokens to generate",
            "temperature": "Controls randomness in responses (0.0 = deterministic, 2.0 = very creative)",
            "top_p": "Controls diversity via nucleus sampling (not supported by grok-4)",
            "live_search": "Enable agentic search capabilities: 'off' (disabled), 'web search', 'x search', 'full' (web + x + code)",
            "store_messages": "Use xAI's server-side memory to maintain conversation context. Memory parameters (TTL, max turns) are configured at integration level and automatically detect user vs device requests.",
            "assistant_name": "The name the assistant will use to identify itself (e.g., 'Grok Code Fast', 'CodeBot', 'DevAssistant'). Changing this value will start a new conversation, and previous history will become inaccessible.",
            "reasoning_effort": "Level of reasoning effort for models that support it (low, medium, high)"
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Configuration updated successfully!"
      }
    }
  }
}

